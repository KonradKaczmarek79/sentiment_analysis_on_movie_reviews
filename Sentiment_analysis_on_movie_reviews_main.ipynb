{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca6c703-0830-49a4-b37f-dd9f8ac6685b",
   "metadata": {},
   "source": [
    "### Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "086cb9ca-53d1-4f32-9a36-49de6114be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import supporting_modules.text_cleaning as stc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41746262-cfd8-4960-867a-2ea10e0dbc5f",
   "metadata": {},
   "source": [
    "## Load data from dataset\n",
    "\n",
    "Firstly, we need to load the dataset for further analysis. In this case, it will be the dataset named **\"Large Movie Review Dataset\"**. It is downloaded from https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "The sentiment values in the text corpus from Stanford Dataset is either positive or negative. More info about these data is in `README` file. After loading, the data is of sklearn Bunch type, so we have to retrieve list of text data and numpy.ndarray with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c48b330-c564-4ae5-9299-1abcd0daae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_files(\"../datasets/aclImdb_v1/aclImdb/train\")\n",
    "test_data = load_files(\"../datasets/aclImdb_v1/aclImdb/test\")\n",
    "\n",
    "reviews_train, y_train = train_data.data, train_data.target\n",
    "reviews_test, y_test = test_data.data, test_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b742a1",
   "metadata": {},
   "source": [
    "The types of each data element are listed below. As we can see the data are saved as bytes. The length of the training data set is equal to 75,000. In the README file, it was mentioned that the quantity of positive and negative reviews is equal to 50,000 (per 25,000 in training and test part accordingly). The difference equal to 50,000 is caused by data labeled as 'unsup'. This part of the data includes an additional 50,000 unlabeled documents for unsupervised learning.\n",
    "\n",
    "In the first part of the project, this data will not be needed. Therefore, they will be subtracted from the training pool (there is no data with this label in the test pool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4657261f-72ee-477b-99d6-e0c28217bd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data data type: <class 'sklearn.utils._bunch.Bunch'>\n",
      "reviews_train type: <class 'list'>\n",
      "the type of single review: <class 'bytes'>\n",
      "reviews_test type: <class 'list'>\n",
      "text_train data length: 75000\n",
      "text_test data length: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_data data type: {type(train_data)}\")\n",
    "print(f\"reviews_train type: {type(reviews_train)}\")\n",
    "print(f\"the type of single review: {type(reviews_train[0])}\")\n",
    "print(f\"reviews_test type: {type(reviews_test)}\")\n",
    "print(f\"text_train data length: {len(reviews_train)}\")\n",
    "print(f\"text_test data length: {len(reviews_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b843ca5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportions of the data distribution: [12500 12500 50000]\n",
      "Numeric values of labels: (array([0, 1, 2]), array([12500, 12500, 50000], dtype=int64))\n",
      "Label names: ['neg', 'pos', 'unsup']\n",
      "\n",
      "The proportions of the data distribution: [12500 12500]\n",
      "Numeric values of labels: (array([0, 1]), array([12500, 12500], dtype=int64))\n",
      "Label names: ['neg', 'pos']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The data in the training set are distributed in the proportions of 12500, 12500, 50000\n",
    "# In next steps I remove those items that are 'unsup', that is, without a clear indication\n",
    "\n",
    "print(f\"The proportions of the data distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Numeric values of labels: {np.unique(y_train, return_counts=True)}\")\n",
    "print(f\"Label names: {train_data.target_names}\\n\")\n",
    "\n",
    "print(f\"The proportions of the data distribution: {np.bincount(y_test)}\")\n",
    "print(f\"Numeric values of labels: {np.unique(y_test, return_counts=True)}\")\n",
    "print(f\"Label names: {test_data.target_names}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b16219e-d37e-42ec-8d68-cb44ff01790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE REVIEW EXAMPLE:\n",
      " b\"Dan Katzir has produced a wonderful film that takes us on a roller-coaster ride through a real romance set in the troubles surrounding modern Israel.<br /><br />For anyone who's ever been in love, the film brings back the uncertainties, the insecurities and heartache that make love so bitter-sweet. The atmosphere of fear and isolation that came with the difficult times in Israel at that time just serve to intensify the feeling. Instantly, you are drawn in to Dan's plight, and you can't fail to be deeply moved.<br /><br />You can't write drama and passion like this - the contrast between the realities of Dan's desperate, snatched relationship with Iris, and the realities of a state in turmoil make this eminently watchable. If you have an ounce of passion, and have ever been in love, see this film.\" \n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "NEGATIVE REVIEW EXAMPLE:\n",
      " b\"This film comes as the ultimate disappointment in Tsai Ming-Liang for me. It oozes laziness from its every frame. So I'm not going to analyse it thoroughly either. But some observations:<br /><br />1. If the premise is drought, why we get to see city landscapes with blooming green trees? I wonder if that was supposed to mean something in the metaphorical context of the film (in which thirst notifies the craving for intimacy, and watermelon the trivial substitute, sex). Or it is only a matter of lousy film-making, not giving a damn about being coherent.<br /><br />2. We don't get to know what had happened to the porn actress, why she is unconscious or, presumably, dead. It seems a question of no importance as long as the message of supreme alienation is successfully (=bombastically) delivered, but in retrospect, her inert body proves to be a cheap dramaturgical gimmick, a pretext \\xc2\\x96 just as gratuitous and exploitative as the activity it is employed in.<br /><br />3. Nothing is expressed in this movie that Antonioni hadn't expressed better 40 years ago \\xc2\\x96 and without needlessly humiliating his actors.<br /><br />4. The musical numbers (recycled from 'The Hole') felt like a secondary-schooler's idea of artistic counterpointing, executed on that very secondary-school level of skill. If that was the point, the point sucked.\"\n"
     ]
    }
   ],
   "source": [
    "# lets see how the reviews looks like\n",
    "\n",
    "print(\"POSITIVE REVIEW EXAMPLE:\\n\".upper(), reviews_train[3], \"\\n\\n\", \"*\" * 100, \"\\n\")\n",
    "print(\"NEGATIVE REVIEW EXAMPLE:\\n\", reviews_train[126])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2572a5",
   "metadata": {},
   "source": [
    "## Remove the data without labels\n",
    "\n",
    "The data are cleaned using function defined in `additional_modules/test_cleaning`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dc9794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_binary, y_train_binary = stc.clear_reviews_from_dataset(y_train, reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee5cbcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportions of the data distribution: [12500 12500]\n",
      "Numeric values of labels: (array([0, 1]), array([12500, 12500], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Our data after applying stc.clear_reviews_from_dataset() function\n",
    "\n",
    "print(f\"The proportions of the data distribution: {np.bincount(y_train_binary)}\")\n",
    "print(f\"Numeric values of labels: {np.unique(y_train_binary, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334636c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
